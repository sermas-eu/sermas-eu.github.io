"use strict";(self.webpackChunksermas_eu_github_io=self.webpackChunksermas_eu_github_io||[]).push([[5736],{582:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"agent/llm/mistral","title":"Mistral","description":"Mistral has an offering for chat inference and embedding","source":"@site/docs/agent/llm/mistral.md","sourceDirName":"agent/llm","slug":"/agent/llm/mistral","permalink":"/docs/agent/llm/mistral","draft":false,"unlisted":false,"editUrl":"https://github.com/sermas-eu/sermas-eu.github.io/sidebar.ts/docs/agent/llm/mistral.md","tags":[],"version":"current","sidebarPosition":0.00018,"frontMatter":{"sidebar_position":0.00018},"sidebar":"tutorialSidebar","previous":{"title":"GCP Mistral","permalink":"/docs/agent/llm/gcp_mistral"},"next":{"title":"Vertex AI","permalink":"/docs/agent/llm/vertexai"}}');var a=n(4848),r=n(8453);const s={sidebar_position:18e-5},o="Mistral",l={},c=[{value:"Configure the Toolkit API",id:"configure-the-toolkit-api",level:2}];function d(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"mistral",children:"Mistral"})}),"\n",(0,a.jsx)(t.p,{children:"Mistral has an offering for chat inference and embedding"}),"\n",(0,a.jsxs)(t.p,{children:["Check Mistral docs to ",(0,a.jsx)(t.a,{href:"https://console.mistral.ai/api-keys/",children:"obtain an api key"})]}),"\n",(0,a.jsx)(t.h2,{id:"configure-the-toolkit-api",children:"Configure the Toolkit API"}),"\n",(0,a.jsxs)(t.p,{children:["Locate the file ",(0,a.jsx)(t.code,{children:"./config/api/.env"})," and add the following configurations"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-ini",children:"LLM_SERVICE=mistral\n\n# MISTRAL_API_KEY Mistral api key\nMISTRAL_API_KEY=''\n\n# MISTRAL_EMBEDDINGS_MODEL OpenAi Embedding model\nMISTRAL_EMBEDDINGS_MODEL='mistral-embed'\n\n# MISTRAL_CHAT_MODELS Supported chat models from OpenAI. Leave empty to allow all available.\nMISTRAL_CHAT_MODELS=\n'open-mistral-nemo,open-mistral-7b,open-mixtral-8x7b,open-mixtral-8x22b,mistral-large-latest'\n\n# MISTRAL_MODEL Default OpenAI model used as fallback\nMISTRAL_MODEL='open-mistral-nemo'\n\n"})})]})}function m(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>o});var i=n(6540);const a={},r=i.createContext(a);function s(e){const t=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),i.createElement(r.Provider,{value:t},e.children)}}}]);