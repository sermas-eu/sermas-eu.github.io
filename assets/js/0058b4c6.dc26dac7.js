"use strict";(self.webpackChunksermas_eu_github_io=self.webpackChunksermas_eu_github_io||[]).push([[849],{6164:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Overview","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/docs/overview/introduction","docId":"overview/introduction","unlisted":false},{"type":"link","label":"Architecture","href":"/docs/overview/architecture","docId":"overview/architecture","unlisted":false}],"href":"/docs/category/overview"},{"type":"category","label":"Getting Started","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"System setup","href":"/docs/getting-started/system-setup","docId":"getting-started/system-setup","unlisted":false},{"type":"link","label":"Create an application","href":"/docs/getting-started/create-application","docId":"getting-started/create-application","unlisted":false}],"href":"/docs/category/getting-started"},{"type":"category","label":"Applications","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/docs/applications/introduction","docId":"applications/introduction","unlisted":false},{"type":"link","label":"Settings","href":"/docs/applications/app-settings","docId":"applications/app-settings","unlisted":false},{"type":"link","label":"CLI management","href":"/docs/applications/cli-handling","docId":"applications/cli-handling","unlisted":false}],"href":"/docs/category/applications"},{"type":"category","label":"LLM configuration","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Introduction","href":"/docs/llm/introduction","docId":"llm/introduction","unlisted":false},{"type":"link","label":"Gemini","href":"/docs/llm/gemini","docId":"llm/gemini","unlisted":false},{"type":"link","label":"Groq","href":"/docs/llm/groq","docId":"llm/groq","unlisted":false},{"type":"link","label":"Hugging Face","href":"/docs/llm/huggingface","docId":"llm/huggingface","unlisted":false},{"type":"link","label":"Antrophic","href":"/docs/llm/antrophic","docId":"llm/antrophic","unlisted":false},{"type":"link","label":"Mistral","href":"/docs/llm/mistral","docId":"llm/mistral","unlisted":false},{"type":"link","label":"Ollama","href":"/docs/llm/ollama","docId":"llm/ollama","unlisted":false},{"type":"link","label":"OpenAI","href":"/docs/llm/openai","docId":"llm/openai","unlisted":false}],"href":"/docs/category/llm-configuration"},{"type":"category","label":"CLI","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Setup","href":"/docs/sermas-cli/setup","docId":"sermas-cli/setup","unlisted":false},{"type":"link","label":"Usage","href":"/docs/sermas-cli/usage","docId":"sermas-cli/usage","unlisted":false}],"href":"/docs/category/cli"},{"type":"category","label":"Toolkit API","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Configuration","href":"/docs/toolkit-api/configuration","docId":"toolkit-api/configuration","unlisted":false}],"href":"/docs/category/toolkit-api"},{"type":"category","label":"ROS Proxy","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Usage","href":"/docs/sermas-ros-proxy/usage","docId":"sermas-ros-proxy/usage","unlisted":false}],"href":"/docs/category/ros-proxy"},{"type":"category","label":"FAQs & Troubleshooting","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Troubleshooting","href":"/docs/faqs-and-troubleshooting/troubleshooting","docId":"faqs-and-troubleshooting/troubleshooting","unlisted":false}],"href":"/docs/category/faqs--troubleshooting"}]},"docs":{"applications/app-settings":{"id":"applications/app-settings","title":"Settings","description":"Application settings are used as defaults in new interactions.","sidebar":"tutorialSidebar"},"applications/cli-handling":{"id":"applications/cli-handling","title":"CLI management","description":"The SERMAS CLI offer a simplified method to handle an application.","sidebar":"tutorialSidebar"},"applications/introduction":{"id":"applications/introduction","title":"Introduction","description":"An application (or app) wraps together the configuration for different components available in the SERMAS Toolkit.","sidebar":"tutorialSidebar"},"faqs-and-troubleshooting/troubleshooting":{"id":"faqs-and-troubleshooting/troubleshooting","title":"Troubleshooting","description":"Error opening an app","sidebar":"tutorialSidebar"},"getting-started/create-application":{"id":"getting-started/create-application","title":"Create an application","description":"To create an application, we are going to use the SERMAS CLI","sidebar":"tutorialSidebar"},"getting-started/system-setup":{"id":"getting-started/system-setup","title":"System setup","description":"Let\'s discover SERMAS in ~10 minutes.","sidebar":"tutorialSidebar"},"llm/antrophic":{"id":"llm/antrophic","title":"Antrophic","description":"Antrophic has an offering for chat inference","sidebar":"tutorialSidebar"},"llm/gemini":{"id":"llm/gemini","title":"Gemini","description":"Gemini offers a simplified access to the LLM offering by Google.","sidebar":"tutorialSidebar"},"llm/groq":{"id":"llm/groq","title":"Groq","description":"Groq offers probably the fastest LLM inference service as of writing. Unfortunately, the billing settings are not yet avail and the free tier is limited.","sidebar":"tutorialSidebar"},"llm/huggingface":{"id":"llm/huggingface","title":"Hugging Face","description":"Hugging Face offers a Pro subscription for LLM inference and custom hardware for enterprise usage","sidebar":"tutorialSidebar"},"llm/introduction":{"id":"llm/introduction","title":"Introduction","description":"Follow some guidance to configure different LLM providers from those supported.","sidebar":"tutorialSidebar"},"llm/mistral":{"id":"llm/mistral","title":"Mistral","description":"Mistral has an offering for chat inference and embedding","sidebar":"tutorialSidebar"},"llm/ollama":{"id":"llm/ollama","title":"Ollama","description":"Let\'s setup a local LLMs service to run inference.","sidebar":"tutorialSidebar"},"llm/openai":{"id":"llm/openai","title":"OpenAI","description":"OpenAI offers chat completions and embeddings suport. Additionaly it covers STT/TTS and real time interaction API.","sidebar":"tutorialSidebar"},"overview/architecture":{"id":"overview/architecture","title":"Architecture","description":"Agents","sidebar":"tutorialSidebar"},"overview/introduction":{"id":"overview/introduction","title":"Introduction","description":"SERMAS focus on developing methods and tools to help future XR systems be socially accepted.","sidebar":"tutorialSidebar"},"sermas-cli/setup":{"id":"sermas-cli/setup","title":"Setup","description":"The SERMAS CLI offers an interface to manage and configure the SERMAS Toolkit API","sidebar":"tutorialSidebar"},"sermas-cli/usage":{"id":"sermas-cli/usage","title":"Usage","description":"- SERMAS CLI overview","sidebar":"tutorialSidebar"},"sermas-ros-proxy/usage":{"id":"sermas-ros-proxy/usage","title":"Usage","description":"The SERMAS ROS Proxy is a ROS2 (https://ros.org) node that allow the communication between the SERMAS toolkit and a ROS environment.","sidebar":"tutorialSidebar"},"toolkit-api/configuration":{"id":"toolkit-api/configuration","title":"Configuration","description":"The Toolkit API can be configured using different sets of environment variables","sidebar":"tutorialSidebar"}}}}')}}]);