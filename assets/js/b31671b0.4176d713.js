"use strict";(self.webpackChunksermas_eu_github_io=self.webpackChunksermas_eu_github_io||[]).push([[6357],{7015:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"llm/mistral","title":"Mistral","description":"Mistral has an offering for chat inference and embedding","source":"@site/docs/llm/mistral.md","sourceDirName":"llm","slug":"/llm/mistral","permalink":"/docs/llm/mistral","draft":false,"unlisted":false,"editUrl":"https://github.com/sermas-eu/sermas-eu.github.io/sidebar.ts/docs/llm/mistral.md","tags":[],"version":"current","sidebarPosition":0.00018,"frontMatter":{"sidebar_position":0.00018},"sidebar":"tutorialSidebar","previous":{"title":"Antrophic","permalink":"/docs/llm/antrophic"},"next":{"title":"Ollama","permalink":"/docs/llm/ollama"}}');var a=t(4848),r=t(8453);const s={sidebar_position:18e-5},o="Mistral",l={},c=[{value:"Configure the Toolkit API",id:"configure-the-toolkit-api",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"mistral",children:"Mistral"})}),"\n",(0,a.jsx)(n.p,{children:"Mistral has an offering for chat inference and embedding"}),"\n",(0,a.jsxs)(n.p,{children:["Check Mistral docs to ",(0,a.jsx)(n.a,{href:"https://console.mistral.ai/api-keys/",children:"obtain an api key"})]}),"\n",(0,a.jsx)(n.h2,{id:"configure-the-toolkit-api",children:"Configure the Toolkit API"}),"\n",(0,a.jsxs)(n.p,{children:["Locate the file ",(0,a.jsx)(n.code,{children:"./config/api/.env"})," and add the following configurations"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ini",children:"LLM_SERVICE=mistral\n\n# MISTRAL_API_KEY Mistral api key\nMISTRAL_API_KEY=''\n\n# MISTRAL_EMBEDDINGS_MODEL OpenAi Embedding model\nMISTRAL_EMBEDDINGS_MODEL='mistral-embed'\n\n# MISTRAL_CHAT_MODELS Supported chat models from OpenAI. Leave empty to allow all available.\nMISTRAL_CHAT_MODELS=\n'open-mistral-nemo,open-mistral-7b,open-mixtral-8x7b,open-mixtral-8x22b,mistral-large-latest'\n\n# MISTRAL_MODEL Default OpenAI model used as fallback\nMISTRAL_MODEL='open-mistral-nemo'\n\n"})})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>o});var i=t(6540);const a={},r=i.createContext(a);function s(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);