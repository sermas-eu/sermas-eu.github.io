"use strict";(self.webpackChunksermas_eu_github_io=self.webpackChunksermas_eu_github_io||[]).push([[5736],{582:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"agent/llm/mistral","title":"Mistral","description":"Mistral has an offering for chat inference and embedding","source":"@site/docs/agent/llm/mistral.md","sourceDirName":"agent/llm","slug":"/agent/llm/mistral","permalink":"/docs/agent/llm/mistral","draft":false,"unlisted":false,"editUrl":"https://github.com/sermas-eu/sermas-eu.github.io/sidebar.ts/docs/agent/llm/mistral.md","tags":[],"version":"current","sidebarPosition":0.00018,"frontMatter":{"sidebar_position":0.00018},"sidebar":"tutorialSidebar","previous":{"title":"Antrophic","permalink":"/docs/agent/llm/antrophic"},"next":{"title":"Ollama","permalink":"/docs/agent/llm/ollama"}}');var i=t(4848),r=t(8453);const s={sidebar_position:18e-5},o="Mistral",l={},c=[{value:"Configure the Toolkit API",id:"configure-the-toolkit-api",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"mistral",children:"Mistral"})}),"\n",(0,i.jsx)(n.p,{children:"Mistral has an offering for chat inference and embedding"}),"\n",(0,i.jsxs)(n.p,{children:["Check Mistral docs to ",(0,i.jsx)(n.a,{href:"https://console.mistral.ai/api-keys/",children:"obtain an api key"})]}),"\n",(0,i.jsx)(n.h2,{id:"configure-the-toolkit-api",children:"Configure the Toolkit API"}),"\n",(0,i.jsxs)(n.p,{children:["Locate the file ",(0,i.jsx)(n.code,{children:"./config/api/.env"})," and add the following configurations"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ini",children:"LLM_SERVICE=mistral\n\n# MISTRAL_API_KEY Mistral api key\nMISTRAL_API_KEY=''\n\n# MISTRAL_EMBEDDINGS_MODEL OpenAi Embedding model\nMISTRAL_EMBEDDINGS_MODEL='mistral-embed'\n\n# MISTRAL_CHAT_MODELS Supported chat models from OpenAI. Leave empty to allow all available.\nMISTRAL_CHAT_MODELS=\n'open-mistral-nemo,open-mistral-7b,open-mixtral-8x7b,open-mixtral-8x22b,mistral-large-latest'\n\n# MISTRAL_MODEL Default OpenAI model used as fallback\nMISTRAL_MODEL='open-mistral-nemo'\n\n"})})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>o});var a=t(6540);const i={},r=a.createContext(i);function s(e){const n=a.useContext(r);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),a.createElement(r.Provider,{value:n},e.children)}}}]);