"use strict";(self.webpackChunksermas_eu_github_io=self.webpackChunksermas_eu_github_io||[]).push([[3361],{9722:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"llm/groq","title":"Groq","description":"Groq offers probably the fastest LLM inference service as of writing. Unfortunately, the billing settings are not yet avail and the free tier is limited.","source":"@site/docs/llm/groq.md","sourceDirName":"llm","slug":"/llm/groq","permalink":"/docs/llm/groq","draft":false,"unlisted":false,"editUrl":"https://github.com/sermas-eu/sermas-eu.github.io/sidebar.ts/docs/llm/groq.md","tags":[],"version":"current","sidebarPosition":0.00014,"frontMatter":{"sidebar_position":0.00014},"sidebar":"tutorialSidebar","previous":{"title":"Gemini","permalink":"/docs/llm/gemini"},"next":{"title":"Hugging Face","permalink":"/docs/llm/huggingface"}}');var i=n(4848),r=n(8453);const a={sidebar_position:14e-5},s="Groq",l={},c=[{value:"Configure the Toolkit API",id:"configure-the-toolkit-api",level:2}];function d(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"groq",children:"Groq"})}),"\n",(0,i.jsx)(t.p,{children:"Groq offers probably the fastest LLM inference service as of writing. Unfortunately, the billing settings are not yet avail and the free tier is limited."}),"\n",(0,i.jsxs)(t.p,{children:["Check Groq docs to ",(0,i.jsx)(t.a,{href:"https://console.groq.com/keys",children:"obtain an api key"})]}),"\n",(0,i.jsx)(t.h2,{id:"configure-the-toolkit-api",children:"Configure the Toolkit API"}),"\n",(0,i.jsxs)(t.p,{children:["Locate the file ",(0,i.jsx)(t.code,{children:"./config/api/.env"})," and add the following configurations"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-ini",children:"LLM_SERVICE=groq\n\n# GROQ_API_KEY Provide Groq api key for chat\nGROQ_API_KEY='api key'\n\n## the following are the defaults, edit if needed\n\n# GROQ_MODEL Default Groq model used as fallback\nGROQ_MODEL='mixtral-8x7b-32768'\n\n# GROQ_CHAT_MODELS Supported chat models from Groq. Leave empty to allow all available.\nGROQ_CHAT_MODELS='gemma-7b-it,gemma2-9b-it,llama2-70b-4096,llama3-70b-8192,llama3-8b-8192,mixtral-8x7b-32768,llama3-groq-8b-8192-tool-use-preview,llama3-groq-70b-8192-tool-use-preview'\n\n"})})]})}function u(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>s});var o=n(6540);const i={},r=o.createContext(i);function a(e){const t=o.useContext(r);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),o.createElement(r.Provider,{value:t},e.children)}}}]);